{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Understanding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import count_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Cyclists Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_df = pd.read_csv('../dataset/cyclists.csv')\n",
    "\n",
    "cyclists_numeric = [\"birth_year\", \"height\", \"weight\"]\n",
    "cyclists_categorical = [\"nationality\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Basic Checks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • Attribute Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From an initial check there are no particular anomalies in the attribute types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • Non-Null Values Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot a histogram showing how many null values there are for each attribute to get a more clear view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of null values for each column\n",
    "null_counts = cyclists_df.isnull().sum()\n",
    "\n",
    "# Plot the histogram\n",
    "null_counts.plot(kind='bar', figsize=(10, 6), title='Histogram of Null Values for Each Column in Cyclists Dataset')\n",
    "plt.xlabel('Attributes')\n",
    "plt.ylabel('Number of Null Values')\n",
    "# Add y values over the columns\n",
    "for i, v in enumerate(null_counts):\n",
    "    plt.text(i, v + 50, str(v), ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attributes with the most null values are weight and height."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Basic Statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_df[cyclists_numeric].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We briefly validate the min/max values querying the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min values corresponding cyclists:')\n",
    "print(f'- {cyclists_df[cyclists_df[\"birth_year\"] == 1933][\"name\"].values[0]} was born in 1933')\n",
    "print(f'- {cyclists_df[cyclists_df[\"height\"] == 154][\"name\"].values[0]} was tall 154 cm')\n",
    "print(f'- {cyclists_df[cyclists_df[\"weight\"] == 48][\"name\"].values[0]} weighted 48 kg')\n",
    "\n",
    "print()\n",
    "\n",
    "print('Max values corresponding cyclists:')\n",
    "print(f'- {cyclists_df[cyclists_df[\"birth_year\"] == 2004][\"name\"].values[0]} was born in 2004')\n",
    "print(f'- {cyclists_df[cyclists_df[\"height\"] == 204][\"name\"].values[0]} was tall 204 cm')\n",
    "print(f'- {cyclists_df[cyclists_df[\"weight\"] == 94][\"name\"].values[0]} weighted 94 kg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of this data are real according to the web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Columns Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```_url``` column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This categorical column contains the unique URL identifier of a cyclist. As we can see after a simple check, the 6134 total values are unique: there are no duplicates in the column nor null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cyclists_df['_url'].duplicated().sum(), 'duplicates found')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_df['_url'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```Name``` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a categorical column containing the name of a cyclist. As we can see by a first check, there are 7 duplicates in the column. So we analyze them in details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cyclists_df['name'].duplicated().sum(), 'duplicates found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the ```_url_``` values are unique we exclude that there are duplicates. Indeed, by visualising which duplicates are in the ```name``` column and their associated ```_url_``` values, we can assume that they are different people since, for istance, ```Sergio Domínguez``` is associated to ```sergio-dominguez-rodriguez``` and ```sergio-dominguez-munoz``` which are two existent and different cyclists. \n",
    "\n",
    "In this example, therefore, the value in the name column is simply a shortened name that is associated with two different cyclists. In case the extended name is the same, we can see that the ```_url_``` value contains a number in the tail to identify the two different cyclists. For example, ```Alessandro Pozzi``` or ```Andrea Peron``` are associated respectively with ```alessandro-pozzi```, ```alessandro-pozzi2``` and ```andrea-peron```, ```andrea-peron-1```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_df[cyclists_df.duplicated(subset='name', keep=False)][['_url', 'name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_df[cyclists_df['name'].isin(['Andrea  Peron', 'Alessandro  Pozzi'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, an online search allowed us to verify that these are four different people, and also validated the data associated with them in the other columns of the dataset. \n",
    "\n",
    "Apparently no standard is used in the ```_url_``` values to mark two different cyclists. For example, there are two cyclists in the dataset:```Jesús López Carril``` (1949) and ```Jesús López Soriano``` (1955). For the fisrt one, the ```_url``` is ```jesus-lopez-carril``` as expected. For the second one we would have expected an ```_url``` value like ```jesus-lopez-soriano```, instead it is ```jesus-lopez23```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_df[cyclists_df['name'] == 'Jesús  López']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```birth_year``` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a numerical attribute indicating the birth year of a cyclist. For obvious reasons duplicates are allowed. We check if there are null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(cyclists_df['birth_year'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are only 13 null values we show all the related rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_df[cyclists_df['birth_year'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the table above, also the ```weight``` and ```height``` values are ```NaN``` when ```birth_year``` is null."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we previously checked in the basic analysis there are some outliers (extreme values) in the min/max values of  column, already verified (see previous analysis). We also check if in the middle there are some errors in the ```birth_year``` values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_df['birth_year'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there are only legal values in the column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(cyclists_df['birth_year'].dropna(), binwidth=1)\n",
    "plt.title('birth_year distribution')\n",
    "plt.xlabel('Birth Year')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_df[cyclists_df['birth_year'] == 2004]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: comment histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 10))\n",
    "sns.boxplot(y=cyclists_df['birth_year'])\n",
    "plt.title('Boxplot of Birth Year')\n",
    "plt.ylabel('Birth Year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count number of outliers using IQR method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import count_outliers\n",
    "count_outliers(cyclists_df['birth_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_df['birth_year'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the distribution of ```birth_year``` is centered in 1974, with most people being born between 1962 and 1987, and the total range spans from 1933 to 2004. There don't seem to be any outliers as no individual points are plotted outside of the whiskers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```weight``` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a numerical attribute. Duplicates are allowed for obvious reasons. We check null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(cyclists_df['weight'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_df[cyclists_df['weight'].isnull()].sample(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3056 ```NaN``` values for the ```weight``` attribute. By picking a small random sample of the rows where  the ```weight``` attribute is ```NaN``` we notice that also the ```height``` is ```NaN```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(cyclists_df['weight'].dropna(), binwidth=1)\n",
    "plt.title('weight distribution')\n",
    "plt.xlabel('weight')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: comment the histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 10))\n",
    "sns.boxplot(y=cyclists_df['weight'])\n",
    "plt.title('Boxplot of weight')\n",
    "plt.ylabel('Weight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count number of  outliers basing on IQR method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import count_outliers\n",
    "count_outliers(cyclists_df['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_df['weight'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some outliers, more concentrated on the upper whisker. This, together with the other characteristics of the boxplot suggests positive skewness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```height``` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a numerical attribute. Duplicates are allowed for obvious reasons. We check null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(cyclists_df['height'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2991 ```NaN``` values for the ```height``` attribute. As mentioned above, it is very likely to find a ```NaN``` in ```height``` column when even ```weight``` is ```NaN```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(cyclists_df['height'].dropna(), binwidth=1)\n",
    "plt.title('height distribution')\n",
    "plt.xlabel('height')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 10))\n",
    "sns.boxplot(y=cyclists_df['height'])\n",
    "plt.title('Boxplot of height')\n",
    "plt.ylabel('Height')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting number of outliers basing on IQR method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import count_outliers\n",
    "count_outliers(cyclists_df['height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_df['height'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some outliers, this time concentrated more or less equally beyond both the whiskers. The boxplot, together with the histogram plotted before, suggest a relatively symmetric distribution of the ```height``` values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```nationality``` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a categorical attribute. Duplicates are allowed. We check the presence of null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(cyclists_df['nationality'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_df[cyclists_df['nationality'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is only one null value in the ```nationality``` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_df['nationality'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the unique values of ```nationality``` there are apparently no problematic values in the column. All values are semantically and syntactically (check!!!) correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='nationality', data=cyclists_df, order=cyclists_df['nationality'].value_counts().index)\n",
    "plt.title('Histogram of Nationality')\n",
    "plt.xlabel('Nationality')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=90)  # Rotate x-axis labels for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Correlation Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import center_and_scale, correlations, plot_correlations\n",
    "\n",
    "normalized_cyclist, normalization_scalers_cyclist = center_and_scale(cyclists_df)\n",
    "cyclists_corr = correlations(normalized_cyclist)\n",
    "\n",
    "plot_correlations(cyclists_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Races Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df = pd.read_csv('../dataset/races.csv')\n",
    "\n",
    "races_numeric_stage = [\"length\", \"climb_total\", \"startlist_quality\", \"average_temperature\"]\n",
    "races_numeric = [\"position\", \"cyclist_age\", \"delta\"]\n",
    "races_categorical = [\"points\", \"uci_points\", \"profile\"]\n",
    "races_binary = [\"is_tarmac\", \"is_cobbled\", \"is_gravel\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Basic Checks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### • Attributes types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### • Check null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of null values for each column\n",
    "null_counts = races_df.isnull().sum()\n",
    "\n",
    "# Plot the histogram\n",
    "ax = null_counts.plot(kind='bar', figsize=(10, 6), title='Histogram of Null Values for Each Column in Races Dataset')\n",
    "plt.xlabel('Attributes')\n",
    "plt.ylabel('Number of Null Values')\n",
    "\n",
    "# Add y values over the columns, rotating only for \"climb_total\" and \"profile\"\n",
    "for i, v in enumerate(null_counts):\n",
    "    if null_counts.index[i] in [\"climb_total\", \"profile\"]:\n",
    "        ax.text(i, v + 50, str(v), ha='center', va='bottom', rotation=45)\n",
    "    else:\n",
    "        ax.text(i, v + 50, str(v), ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### • Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easy to observe that for each entry related to a stage of a race, different cyclists should be associated. We therefore check that this is true and that there are no duplicates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by '_url' and 'cyclist' and count the occurrences\n",
    "duplicate_cyclists = races_df.groupby(['_url', 'cyclist']).size().reset_index(name='count')\n",
    "\n",
    "# Filter the groups where count is greater than 1\n",
    "duplicate_cyclists = duplicate_cyclists[duplicate_cyclists['count'] > 1]\n",
    "\n",
    "# Display the duplicate cyclists\n",
    "print(duplicate_cyclists)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that there are 123 duplicates in the dataset that should be handled during the data preparation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Count the duplicate values in the 'cyclist' column with the same value in the '_url' column\n",
    "# duplicate_counts = races_df.groupby('_url')['cyclist'].value_counts()\n",
    "\n",
    "# # filter only cyclists duplicated in the same stage\n",
    "# duplicate_counts = duplicate_counts[duplicate_counts > 1]\n",
    "\n",
    "# duplicate_counts.to_csv('../dataset/cyclist_duplicate.csv', header=True)\n",
    "\n",
    "# #count number of total duplicates in the races dataset\n",
    "# print(\"Number of total duplicates in the races dataset: \", duplicate_counts.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### • Unique values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking unique values for each column in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_points_count = races_df.nunique()\n",
    "print(\"Number of distinct values in 'points':\", distinct_points_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important thing we want to assess is that details of a stage are the same i.e. there are no inconsistent entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_attributes = [\"name\", \"points\", \"uci_points\", \"length\", \"climb_total\", \n",
    "                   \"startlist_quality\", \"average_temperature\", \"is_tarmac\"] #TODO: siamo sicuri che ci siano tutti gli attributi?\n",
    "\n",
    "# Initialize an empty list to store _url values where inconsistencies are found\n",
    "inconsistent_urls = []\n",
    "\n",
    "# Check for each attribute in race_attributes\n",
    "for attribute in race_attributes:\n",
    "    # Group by _url and check if all values in the group are the same\n",
    "    inconsistent = races_df.groupby('_url')[attribute].nunique() > 1\n",
    "    # Append the _url values with inconsistencies to the list\n",
    "    inconsistent_urls.extend(inconsistent[inconsistent].index.tolist())\n",
    "\n",
    "# Display the inconsistent _url values\n",
    "print(\"Inconsistent _url values:\", len(inconsistent_urls))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_numeric_stage = [\"length\", \"climb_total\", \"startlist_quality\", \"average_temperature\"]\n",
    "\n",
    "races_numeric_stage.append(\"_url\")\n",
    "\n",
    "numeric_df = races_df[races_numeric_stage].groupby(\"_url\").first().reset_index()\n",
    "\n",
    "numeric_df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Columns Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```_url``` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df['_url'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This column contains the unique identifier of a race's stage. There are in total 5281 different _url values. An _url is in the format \"RACE_NAME/RACE_DATE/STAGE_NUMBER\". For example, the URL \"tour-de-france/1978/stage-6\" denotes the 6th stage of the Tour de France, 1978 edition. It is associated to some race stage details TODO: evaluate adding which are the details?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, if we look only at the column itself, we will find duplicate values. However, by looking at the first ten rows of the table, we assume that there is an entry for each rider who participated in a given stage. Given this observation, we already checked that there are no duplicates for the same stage in terms of participating riders (see the above Duplicate section for the results)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```name``` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attribute is categorical. First of all we check if there are null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df['name'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df['name'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no null values in the column which contains 61 unique values. They are the names of different races. We show those values to check in a qualitative way if there are some errors TODO: check the correct term to identify errors (e.g. \"asfdnajsfa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df['name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the _url column at the first '/' and take the first part\n",
    "race_names = races_df['_url'].str.split('/', n=1).str[0]\n",
    "# Count the unique values\n",
    "race_names.nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in races_df.groupby('name'):\n",
    "    print(f\"Race Name: {name}\")\n",
    "    unique_urls = group['_url'].str.split('/', n=1).str[0].unique()\n",
    "    print(unique_urls)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the total race names used in the unique identifier are only 27. This is because, as we show below, the same RACE_NAME part of the identifier is associated to different values in the names column. This does not mean that the same identifier is associated with different races. Rather, the values in the name column for the same race differ only by a few letters (e.g. e instead of è) or because the race has adopted a different name over the years or is simply known by different names. \n",
    "\n",
    "In particular:\n",
    "- ```san-sebastian``` is associated to _Clasica Ciclista San Sebastian_, _Clásica Ciclista San Sebastian_, _Clásica Ciclista San Sebastián_, _Clásica San Sebastián_, _Donostia San Sebastian Klasikoa_\n",
    "- ```dauphine``` is associated to _Criterium du Dauphiné_, _Criterium du Dauphiné Libére_, _Critérium du Dauphiné_, _Critérium du Dauphiné Libéré_\n",
    "- ```dwars-door-vlaanderen``` is associated to _Dwars door België / À travers la Belgique_, _Dwars door Vlaanderen_, _Dwars door Vlaanderen - A travers la Flandre ME_, _Dwars door Vlaanderen / A travers la Flandre_, _Dwars door Vlaanderen / A travers la Flandre ME_\n",
    "- ```e3-harelbeke``` is associated to _E3 BinckBank Classic_, _E3 Harelbeke_, _E3 Prijs Vlaanderen_, _E3 Prijs Vlaanderen - Harelbeke_, _E3 Saxo Bank Classic_, _E3 Saxo Classic_, _E3-Prijs Harelbek_\n",
    "- ```gp-quebec``` is associated to _Grand Prix Cycliste de Quebec_, _Grand Prix Cycliste de Québec_\n",
    "- ```liege-bastogne-liege``` is associated to _Liège - Bastogne - Liège_, _Liège-Bastogne-Liège_\n",
    "- ```strade-bianche``` is associated to _Monte Paschi Eroica_, _Montepaschi Strade Bianche - Eroica Toscana_, _Strade Bianche_\n",
    "- ```omloop-het-nieuwsblad``` is associated to _Omloop Het Nieuwsblad ME_, _Omloop Het Volk_, _Omloop Het Volk ME_\n",
    "- ```paris-roubaix``` is associated to _Paris - Roubaix_, _Paris-Roubaix_\n",
    "- ```ronde-van-vlaanderen``` is associated to _Ronde van Vlaanderen - Tour des Flandres ME_, _Ronde van Vlaanderen / Tour des Flandres_, _Ronde van Vlaanderen / Tour des Flandres ME_\n",
    "- ```volta-a-catalunya``` is associated to _Volta Ciclista a Catalunya_, _Volta a Catalunya_\n",
    "- ```itzulia-basque-country``` is associated to _Vuelta Ciclista al País Vasco_, _Vuelta al País Vasco_\n",
    "- ```world-championship``` is associated to _World Championships - Road Race_, _World Championships ME - Road Race_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```points``` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a numerical attribute. Same points for different cyclist are supposedly allowed. We check now for null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(races_df['points'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df['points'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df['points'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(races_df['points'].dropna(), bins=30, kde=False)\n",
    "plt.title('Histogram of Points')\n",
    "plt.ylabel('Points')\n",
    "plt.xlabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 10))\n",
    "sns.boxplot(y=races_df['points'])\n",
    "plt.title('Boxplot of Points')\n",
    "plt.ylabel('Points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting number of outliers basing on IQR method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import count_outliers\n",
    "count_outliers(races_df['points'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```uci_points``` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(races_df['uci_points'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df['uci_points'].dropna().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.histplot(races_df['uci_points'].dropna(), bins=30, kde=False)\n",
    "\n",
    "# Add text labels on each bin with rotation\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    if height > 0:\n",
    "        ax.annotate(f'{int(height)}', (p.get_x() + p.get_width() / 2. + 0.1, height),\n",
    "                    ha='center', va='center', xytext=(0, 25), textcoords='offset points', rotation=90)\n",
    "\n",
    "# Set titles and labels\n",
    "plt.title('Histogram of count values for UCI Points attribute')\n",
    "plt.xlabel('UCI Points')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(races_df['uci_points'].dropna(), bins=30, kde=False)\n",
    "plt.title('Histogram of UCI Points')\n",
    "plt.ylabel('UCI Points')\n",
    "plt.xlabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 10))\n",
    "sns.boxplot(y=races_df['uci_points'])\n",
    "plt.title('Boxplot of UCI Points')\n",
    "plt.ylabel('Points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting number of outliers basing on IQR method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import count_outliers\n",
    "count_outliers(races_df['uci_points'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```length``` column "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this feature is in **races_numeric_stage** so first check is to see if the value length is consistent with all copies of the stages (url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- inconsistency check for 'length' ---\n",
    "\n",
    "length_consistency = races_df.groupby('_url')['length'].nunique()\n",
    "# Filter the groups where the number of unique 'profile' values is greater than 1\n",
    "inconsistent_profiles = length_consistency[length_consistency > 1]\n",
    "# Display the inconsistent '_url' values\n",
    "print(\"Number of inconsistent 'length' values:\", len(inconsistent_profiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **length_df** dataset is created where there are two columns: '_url' of the race (one for each copy) and associated the column 'length'. the value profile is taken from one of the rows where it is present in the original races_df dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- length dataset creation ----\n",
    "\n",
    "# Group by '_url' and select the first non-null value for 'length'\n",
    "length_df = races_df.groupby('_url')['length'].apply(lambda x: x.dropna().iloc[0] if not x.isnull().all() else pd.NA).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- boxplot of 'length' ----\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(y=length_df['length'])\n",
    "plt.title('Boxplot of length')\n",
    "plt.ylabel('length (m)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting number of outliers basing on IQR method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import count_outliers\n",
    "count_outliers(races_df['length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Statistics ----\n",
    "\n",
    "# Column of interest\n",
    "d = length_df['length']\n",
    "# Create a DataFrame to store the statistics\n",
    "stats_df = pd.DataFrame({\n",
    "    'Statistic': ['Null Count', 'Unique Value Counts', 'Mean', 'Max', 'Min', 'Variance', 'Description'],\n",
    "    'Value': [\n",
    "        d.isnull().sum(),\n",
    "        d.nunique(),\n",
    "        d.mean(),\n",
    "        d.max(),\n",
    "        d.min(),\n",
    "        d.var(),\n",
    "        d.describe().to_dict()\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 'length' distribution plot ---\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(length_df['length'].dropna(), binwidth=5000)\n",
    "plt.title('Distribution of Length Attribute')\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think under 50km are all to be discarded ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_stages_count = (length_df['length'] < 50000).sum()\n",
    "print(f\"Number of stages under 50 km: {short_stages_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```climb_total``` column "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this feature is in **races_numeric_stage** so first check is to see if the value length is consistent with all copies of the stages (url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- inconsistency check for 'climb_total' ---\n",
    "\n",
    "climb_consistency = races_df.groupby('_url')['climb_total'].nunique()\n",
    "# Filter the groups where the number of unique 'climb_total' values is greater than 1\n",
    "inconsistent_profiles = climb_consistency[climb_consistency > 1]\n",
    "# Display the inconsistent '_url' values\n",
    "print(\"Number of inconsistent 'climb_total' values:\", len(inconsistent_profiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **climb_df** dataset is created where there are two columns: '_url' of the race (one for each copy) and associated the column 'climb_total'. the value profile is taken from one of the rows where it is present in the original races_df dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- climb_df dataset creation ----\n",
    "\n",
    "# Group by '_url' and select the first non-null value for 'climb_total'\n",
    "climb_df = races_df.groupby('_url')['climb_total'].apply(lambda x: x.dropna().iloc[0] if not x.isnull().all() else pd.NA).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- boxplot -----\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(y=climb_df['climb_total'])\n",
    "plt.title('Boxplot of Race climb')\n",
    "plt.ylabel('Length (meters)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting number of outliers basing on IQR method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import count_outliers\n",
    "count_outliers(races_df['climb_total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Statistics ----\n",
    "\n",
    "# Column of interest\n",
    "d = climb_df['climb_total']\n",
    "# Create a DataFrame to store the statistics\n",
    "stats_df = pd.DataFrame({\n",
    "    'Statistic': ['Null Count', 'Unique Value Counts', 'Mean', 'Max', 'Min', 'Variance', 'Description'],\n",
    "    'Value': [\n",
    "        d.isnull().sum(),\n",
    "        d.nunique(),\n",
    "        d.mean(),\n",
    "        d.max(),\n",
    "        d.min(),\n",
    "        d.var(),\n",
    "        d.describe().to_dict()\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- climb distribution plot ----\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(climb_df['climb_total'].dropna(), binwidth=100)\n",
    "plt.title('Distribution of climb Attribute')\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```profile``` column "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it is in **races_numeric_stage** so first check is to see if the value profile is consistent with all copies of the stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- inconsistency check for profile ---\n",
    "\n",
    "profile_consistency = races_df.groupby('_url')['profile'].nunique()\n",
    "inconsistent_profiles = profile_consistency[profile_consistency > 1]\n",
    "print(\"Number of inconsistent '_url' values:\", len(inconsistent_profiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **profile_df** dataset is created where there are two columns: '_url' of the race (one for each copy) and associated the column 'profile'. the value profile is taken from one of the rows where it is present in the original races_df dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- profile dataset creation ----\n",
    "\n",
    "# Group by '_url' and select the first non-null value for 'profile'\n",
    "profile_df = races_df.groupby('_url')['profile'].apply(lambda x: x.dropna().iloc[0] if not x.isnull().all() else pd.NA).reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are no inconsistencies, we can use **profile_df** dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Statistics ----\n",
    "\n",
    "num_unique_urls = races_df['_url'].nunique()\n",
    "print(f\"Number of unique URLs in races_df: {num_unique_urls}\")\n",
    "num_profile_consistency_rows = len(profile_df)\n",
    "print(f\"Number of rows in profile_consistency: {num_profile_consistency_rows}\")\n",
    "num_null_profile_consistency = profile_df['profile'].isnull().sum()\n",
    "print(f\"Number of null values in profile: {num_null_profile_consistency}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Distribution Plot of the 'profile' attribute ---\n",
    "\n",
    "# Print the frequencies of 'profile' in profile_df, excluding NaN values\n",
    "profile_frequencies = profile_df['profile'].dropna().value_counts()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.countplot(x='profile', data=profile_df.dropna(subset=['profile']), width=0.4)\n",
    "plt.title('Profile Distribution')\n",
    "plt.xlabel('Profile')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "for p in ax.patches:\n",
    "    height = int(p.get_height())\n",
    "    ax.annotate(f'{height}', (p.get_x() + p.get_width() / 2., height),\n",
    "                ha='center', va='center', xytext=(0, 5), textcoords='offset points')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```startlist_quality``` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this feature is in **races_numeric_stage** so first check is to see if the value profile is consistent with all copies of the stages (url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- inconsistency check for 'startlist_quality' ---\n",
    "\n",
    "profile_consistency = races_df.groupby('_url')['startlist_quality'].nunique()\n",
    "# Filter the groups where the number of unique 'profile' values is greater than 1\n",
    "inconsistent_profiles = profile_consistency[profile_consistency > 1]\n",
    "# Display the inconsistent '_url' values\n",
    "print(\"Number of inconsistent 'startlist_quality' values:\", len(inconsistent_profiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **startlist_df** dataset is created where there are two columns: '_url' of the race (one for each copy) and associated the column 'startlist'. the value profile is taken from one of the rows where it is present in the original races_df dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- startlist dataset creation ----\n",
    "\n",
    "# Group by '_url' and select the first non-null value for 'startlist_quality'\n",
    "startlistq_df = races_df.groupby('_url')['startlist_quality'].apply(lambda x: x.dropna().iloc[0] if not x.isnull().all() else pd.NA).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- boxplot ---\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(y=startlistq_df['startlist_quality'])\n",
    "plt.title('Boxplot of startlist quality')\n",
    "plt.ylabel('startlist quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting number of outliers basing on IQR method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- count outliers -----\n",
    "count_outliers(startlistq_df['startlist_quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Statistics ----\n",
    "\n",
    "# Column of interest\n",
    "d = startlistq_df['startlist_quality']\n",
    "# Create a DataFrame to store the statistics\n",
    "stats_df = pd.DataFrame({\n",
    "    'Statistic': ['Null Count', 'Unique Value Counts', 'Mean', 'Max', 'Min', 'Variance', 'Description'],\n",
    "    'Value': [\n",
    "        d.isnull().sum(),\n",
    "        d.nunique(),\n",
    "        d.mean(),\n",
    "        d.max(),\n",
    "        d.min(),\n",
    "        d.var(),\n",
    "        d.describe().to_dict()\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 'startlist_quality' distribution plot ---\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(startlistq_df['startlist_quality'].dropna(), bins=50)\n",
    "plt.title('Distribution of Startlist Quality Attribute')\n",
    "plt.xlabel('Startlist Quality')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```date``` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feature could be divetsa for each copy of the stages so it makes no sense to checke possible conisistencies. \n",
    "In stage races, there are different types of starts. In some, all cyclists start together, while in others (time trials), cyclists start one by one based on their ranking, with a few seconds in between (usually 1 minute). In other races (team time trials), teams start one group at a time with a set time gap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_year_df = pd.DataFrame()\n",
    "\n",
    "# Ensure the 'date' column is in datetime format\n",
    "temp_year_df['date'] = pd.to_datetime(races_df['date'])\n",
    "\n",
    "# Extract the year from the 'date' column\n",
    "temp_year_df['year'] = temp_year_df['date'].dt.year\n",
    "\n",
    "# Calculate the minimum, maximum, and average year\n",
    "min_year = temp_year_df['year'].min()\n",
    "max_year = temp_year_df['year'].max()\n",
    "avg_year = temp_year_df['year'].mean()\n",
    "\n",
    "print(f\"Minimum Year: {min_year}\")\n",
    "print(f\"Maximum Year: {max_year}\")\n",
    "print(f\"Average Year: {avg_year:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 10))\n",
    "sns.boxplot(y=temp_year_df['year'])\n",
    "plt.title('Boxplot of Race Year')\n",
    "plt.ylabel('Race Year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```average_temperature``` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this feature is in **races_numeric_stage** so first check is to see if the value profile is consistent with all copies of the stages (url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- inconsistency check for 'average_temperature' ---\n",
    "\n",
    "profile_consistency = races_df.groupby('_url')['average_temperature'].nunique()\n",
    "# Filter the groups where the number of unique 'profile' values is greater than 1\n",
    "inconsistent_profiles = profile_consistency[profile_consistency > 1]\n",
    "# Display the inconsistent '_url' values\n",
    "print(\"Number of inconsistent 'average_temperature' values:\", len(inconsistent_profiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **temp_df** dataset is created where there are two columns: '_url' of the race (one for each copy) and associated the column 'avarage_tempreature'. the value profile is taken from one of the rows where it is present in the original races_df dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- average_temperature dataset creation ----\n",
    "\n",
    "# Group by '_url' and select the first non-null value for 'startlist_quality'\n",
    "temp_year_df = races_df.groupby('_url')['average_temperature'].apply(lambda x: x.dropna().iloc[0] if not x.isnull().all() else pd.NA).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- boxplot ---\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(y=temp_year_df['average_temperature'])\n",
    "plt.title('Boxplot of average temperature')\n",
    "plt.ylabel('average temperature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- count outliers ----\n",
    "\n",
    "count_outliers(temp_year_df['average_temperature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Statistics ----\n",
    "\n",
    "# Column of interest\n",
    "d = temp_year_df['average_temperature']\n",
    "# Create a DataFrame to store the statistics\n",
    "stats_df = pd.DataFrame({\n",
    "    'Statistic': ['Null Count', 'Unique Value Counts', 'Mean', 'Max', 'Min', 'Variance', 'Description'],\n",
    "    'Value': [\n",
    "        d.isnull().sum(),\n",
    "        d.nunique(),\n",
    "        d.mean(),\n",
    "        d.max(),\n",
    "        d.min(),\n",
    "        d.var(),\n",
    "        d.describe().to_dict()\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 'average_temperature' distribution plot ---\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(temp_year_df['average_temperature'].dropna(), bins=50)\n",
    "plt.title('Distribution of temperature Attribute')\n",
    "plt.xlabel('average_temperature')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```position``` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(races_df['position'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the same stage, we check if there are duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by '_url' and check for duplicate positions within each group\n",
    "duplicate_positions = races_df.groupby('_url')['position'].apply(lambda x: x.duplicated(keep=False)).reset_index(drop=True)\n",
    "\n",
    "# Filter the DataFrame to show only the rows with duplicate positions\n",
    "races_df[duplicate_positions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(races_df['position'], bins=30, kde=False)\n",
    "plt.title('Histogram of Position')\n",
    "plt.xlabel('Position')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```cyclist``` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df['cyclist'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no null values in the column. Duplicated are expected but we check if, for the same stage of a race, there are no duplicated cyclists values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df[races_df.duplicated(subset=['_url', 'cyclist'], keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the table above, for the same stage, there are duplicated ```cyclist``` values. We can also notice that in the same rows of a duplicate there are also other altered values like ```date```, ```positivon``` or ```delta```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```cyclist_age``` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a numerical attribute. First of all we check if there are null values and if all the entries are numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df['cyclist_age'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df['cyclist_age'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are 113 null entries but the remaining values are numerical.\n",
    "\n",
    "Duplicates in the column are allowed but no for the same cyclist which can be also duplicated for the same stage as we checked in the previous column analysis. We check if the age reported for each cyclist is consistent across the column to gather more informations for the DP part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'cyclist' and check if there are different 'cyclist_age' values\n",
    "age_inconsistencies = races_df.groupby('cyclist')['cyclist_age'].nunique()\n",
    "\n",
    "# Filter the cyclists with more than one unique age value\n",
    "age_inconsistencies[age_inconsistencies > 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected the same cyclist is associated to more than one age value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(races_df['cyclist_age'].dropna(), bins=30)\n",
    "plt.title('Histogram of Cyclist Age')\n",
    "plt.xlabel('Cyclist Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 10))\n",
    "sns.boxplot(y=races_df['cyclist_age'])\n",
    "plt.title('Boxplot of Cyclist Age')\n",
    "plt.ylabel('Cyclist Age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting number of outliers basing on IQR method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import count_outliers\n",
    "count_outliers(races_df['cyclist_age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```is_tarmac``` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a boolean column. We check the presence of null values, errors, and we plot the distribution of the True and False values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df['is_tarmac'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df['is_tarmac'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 10))\n",
    "sns.histplot(races_df['is_tarmac'], bins=2)\n",
    "plt.title('Histogram of Is Tarmac')\n",
    "plt.xlabel('Is Tarmac')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks([0, 1], ['False', 'True'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```is_cobbled``` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting null values in is_cobbled column\n",
    "int(races_df['is_cobbled'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique values in is_cobbled column\n",
    "races_df['is_cobbled'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that is_cobbled is alway false this column probably will be dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```is_gravel``` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting null values in is_gravel column\n",
    "int(races_df['is_gravel'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df['is_gravel'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that is_gravel is alway false this column probably will be dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```cyclist_team``` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting null values in cyclist_team column\n",
    "int(races_df['cyclist_team'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting how many different team there are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of different teams: {races_df['cyclist_team'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether any cyclist has raced for several teams in his career. Then count them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check groupin by cyclist and aggregating the unique teams\n",
    "cyclist_teams = races_df.groupby('cyclist')['cyclist_team'].unique().reset_index()\n",
    "display(cyclist_teams.head(7))\n",
    "\n",
    "# Filter cyclists who have raced for more than one team\n",
    "cyclists_multiple_teams = cyclist_teams[cyclist_teams['cyclist_team'].apply(lambda x: len(x) > 1)]\n",
    "print(f\"Number of cyclists who have raced for more than one team: {len(cyclists_multiple_teams)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As if it's possible to see in the plot cyclists typically have run with more than one team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting number of unique cyclists for each team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_cyclists_df = races_df.drop_duplicates(subset=['cyclist_team', 'cyclist'])\n",
    "unique_cyclists_per_team = unique_cyclists_df.groupby('cyclist_team')['cyclist'].nunique().reset_index()\n",
    "\n",
    "# Plot the histogram with inverted x and y values\n",
    "plt.figure(figsize=(20, 20))  # Increase the figure height for better readability\n",
    "sns.barplot(y='cyclist_team', x='cyclist', data=unique_cyclists_per_team, order=unique_cyclists_per_team.sort_values('cyclist', ascending=False)['cyclist_team'])\n",
    "plt.title('Number of Unique Cyclists per Team')\n",
    "plt.ylabel('Cyclist Team')\n",
    "plt.xlabel('Number of Unique Cyclists')\n",
    "plt.xticks(rotation=90)  # Rotate x-axis labels for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot shows that all teams has at least one cyclist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by '_url' and 'cyclist' and check the number of unique 'cyclist_team' values\n",
    "team_inconsistencies = races_df.groupby(['_url', 'cyclist'])['cyclist_team'].nunique()\n",
    "# Filter the groups with more than one unique 'cyclist_team' value\n",
    "inconsistent_teams = team_inconsistencies[team_inconsistencies > 1]\n",
    "\n",
    "# Display the inconsistent entries\n",
    "print(f\"Inconsistent cyclist_team values for the same race _url and cyclist id: {len(inconsistent_teams)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```delta``` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting null values in delta column\n",
    "int(races_df[\"delta\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df[\"delta\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_races = races_df[races_df['delta'] <= 10000]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(y=delta_races['delta'].dropna())\n",
    "plt.title('Boxplot of Delta Values')\n",
    "plt.ylabel('Delta')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This row seems to be very noisy, containing negative values (that are not allowed for a delta value that represent how many seconds after the first-placed the cyclist get to the finish). Also to visualize something in the plot value greater then 10k are dropped in the plot so there're very very high value for delta that are very strange for professional races"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count number of outliers using IQR method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import count_outliers\n",
    "count_outliers(races_df['delta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to visualize dfistribution removing some outliers\n",
    "delta_races = races_df[(races_df['delta'] <= 2000) & (races_df['delta'] >= 0)]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(delta_races['delta'].dropna(), bins=100)\n",
    "plt.title('Histogram of Delta Values')\n",
    "plt.xlabel('Delta')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Correlation Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import center_and_scale, correlations, plot_correlations\n",
    "\n",
    "normalized_races, normalization_scalers_races = center_and_scale(races_df)\n",
    "races_corr = correlations(normalized_races.drop(columns=['profile']))\n",
    "\n",
    "plot_correlations(races_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Scatter Plot**: TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Integration**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some data understanding analysis for merged datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking if there are cyclists that not appear in races or vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elements in 'cyclist' column of races_data and not in '_url' column of cyclists_data\n",
    "diff_races_not_in_cyclists = np.setdiff1d(races_df['cyclist'].unique(), cyclists_df['_url'].unique())\n",
    "print(\"In 'races_data' but not in 'cyclists_data':\", diff_races_not_in_cyclists)\n",
    "\n",
    "# Elements in '_url' column of cyclists_data and not in 'cyclist' column of races_data\n",
    "diff_cyclists_not_in_races = np.setdiff1d(cyclists_df['_url'].unique(), races_df['cyclist'].unique())\n",
    "print(\"In 'cyclists_data' but not in 'races_data':\", diff_cyclists_not_in_races)\n",
    "\n",
    "print(races_df['cyclist'].unique().size)\n",
    "\n",
    "len(diff_cyclists_not_in_races)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking if cyclist age column is aligned with cyclist birth year using the stage date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def extract_year(date):\n",
    "    \"\"\" extract the year from a date string \"\"\"\n",
    "    try:\n",
    "        return pd.to_datetime(date).dt.year\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "# Drop rows with NaN values in 'date', 'cyclist_age' and 'birth_year' columns\n",
    "races_df_clean = races_df.dropna(subset=['date', 'cyclist_age'])\n",
    "cyclists_df_clean = cyclists_df.dropna(subset=['birth_year'])\n",
    "\n",
    "# Merge the two dataframes on the 'cyclist' and '_url' columns\n",
    "merged_df_clean = races_df_clean.merge(cyclists_df_clean, left_on='cyclist', right_on='_url', suffixes=('_race', '_cyclist'))\n",
    "\n",
    "# Calculate the birth year from the 'date' and 'cyclist_age' columns\n",
    "merged_df_clean['calculated_birth_year'] = extract_year(merged_df_clean['date']) - merged_df_clean['cyclist_age']\n",
    "\n",
    "# Filter the rows where the calculated birth year does not match the actual birth year\n",
    "wrong_age_clean = merged_df_clean[merged_df_clean['calculated_birth_year'] != merged_df_clean['birth_year']]\n",
    "\n",
    "# Display the 'wrong_age' dataframe\n",
    "print(f\"Number of cyclists with wrong age in ne of the datasets: {len(wrong_age_clean)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
