{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Understanding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Cyclists Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_df = pd.read_csv('../dataset/cyclists.csv')\n",
    "\n",
    "cyclists_numeric = [\"birth_year\", \"height\", \"weight\"]\n",
    "cyclists_categorical = [\"nationality\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Basic Checks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • Attribute Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From an initial check there are no particular anomalies in the attribute types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • Non-Null Values Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot a histogram showing how many null values there are for each attribute to get a more clear view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of null values for each column\n",
    "null_counts = cyclists_df.isnull().sum()\n",
    "\n",
    "# Plot the histogram\n",
    "null_counts.plot(kind='bar', figsize=(10, 6), title='Histogram of Null Values for Each Column in Cyclists Dataset')\n",
    "plt.xlabel('Attributes')\n",
    "plt.ylabel('Number of Null Values')\n",
    "# Add y values over the columns\n",
    "for i, v in enumerate(null_counts):\n",
    "    plt.text(i, v + 50, str(v), ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attributes with the most null values are weight and height."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Basic Statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_df[cyclists_numeric].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We briefly validate the min/max values querying the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min values corresponding cyclists:')\n",
    "print(f'- {cyclists_df[cyclists_df[\"birth_year\"] == 1933][\"name\"].values[0]} was born in 1933')\n",
    "print(f'- {cyclists_df[cyclists_df[\"height\"] == 154][\"name\"].values[0]} was tall 154 cm')\n",
    "print(f'- {cyclists_df[cyclists_df[\"weight\"] == 48][\"name\"].values[0]} weighted 48 kg')\n",
    "\n",
    "print()\n",
    "\n",
    "print('Max values corresponding cyclists:')\n",
    "print(f'- {cyclists_df[cyclists_df[\"birth_year\"] == 2004][\"name\"].values[0]} was born in 2004')\n",
    "print(f'- {cyclists_df[cyclists_df[\"height\"] == 204][\"name\"].values[0]} was tall 204 cm')\n",
    "print(f'- {cyclists_df[cyclists_df[\"weight\"] == 94][\"name\"].values[0]} weighted 94 kg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of this data are real according to the web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This categorical column contains the unique URL identifier of a cyclist. As we can see after a simple check, the 6134 total values are unique: there are no duplicates in the column nor null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cyclists_df['_url'].duplicated().sum(), 'duplicates found')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_df['_url'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a categorical column containing the name of a cyclist. As we can see by a first check, there are 7 duplicates in the column. So we analyze them in details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cyclists_df['name'].duplicated().sum(), 'duplicates found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the ```_url_``` values are unique we exclude that there are duplicates. Indeed, by visualising which duplicates are in the ```name``` column and their associated ```_url_``` values, we can assume that they are different people since, for istance, ```Sergio Domínguez``` is associated to ```sergio-dominguez-rodriguez``` and ```sergio-dominguez-munoz``` which are two existent and different cyclists. \n",
    "\n",
    "In this example, therefore, the value in the name column is simply a shortened name that is associated with two different cyclists. In case the extended name is the same, we can see that the ```_url_``` value contains a number in the tail to identify the two different cyclists. For example, ```Alessandro Pozzi``` or ```Andrea Peron``` are associated respectively with ```alessandro-pozzi```, ```alessandro-pozzi2``` and ```andrea-peron```, ```andrea-peron-1```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_df[cyclists_df.duplicated(subset='name', keep=False)][['_url', 'name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_df[cyclists_df['name'].isin(['Andrea  Peron', 'Alessandro  Pozzi'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, an online search allowed us to verify that these are four different people, and also validated the data associated with them in the other columns of the dataset. \n",
    "\n",
    "Apparently no standard is used in the ```_url_``` values to mark two different cyclists. For example, there are two cyclists in the dataset:```Jesús López Carril``` (1949) and ```Jesús López Soriano``` (1955). For the fisrt one, the ```_url``` is ```jesus-lopez-carril``` as expected. For the second one we would have expected an ```_url``` value like ```jesus-lopez-soriano```, instead it is ```jesus-lopez23```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_df[cyclists_df['name'] == 'Jesús  López']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### birth_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a numerical (?) attribute indicating the birth year of a cyclist. For obvious reasons duplicates are allowed. We check if there are null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(cyclists_df['birth_year'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are only 13 null values we show all the related rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_df[cyclists_df['birth_year'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the table above, also the ```weight``` and ```height``` values are ```NaN``` when ```birth_year``` is null."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(cyclists_df['birth_year'].dropna())\n",
    "plt.title('birth_year distribution')\n",
    "plt.xlabel('Birth Year')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: comment histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 10))\n",
    "sns.boxplot(y=cyclists_df['birth_year'])\n",
    "plt.title('Boxplot of Birth Year')\n",
    "plt.ylabel('Birth Year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_df['birth_year'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the distribution of ```birth_year``` is centered in 1974, with most people being born between 1962 and 1987, and the total range spans from 1933 to 2004. There don't seem to be any outliers as no individual points are plotted outside of the whiskers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a numerical attribute. Duplicates are allowed for obvious reasons. We check null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(cyclists_df['weight'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_df[cyclists_df['weight'].isnull()].sample(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3056 ```NaN``` values for the ```weight``` attribute. By picking a small random sample of the rows where  the ```weight``` attribute is ```NaN``` we notice that also the ```height``` is ```NaN```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(cyclists_df['weight'].dropna(), binwidth=1)\n",
    "plt.title('weight distribution')\n",
    "plt.xlabel('weight')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: comment the histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 10))\n",
    "sns.boxplot(y=cyclists_df['weight'])\n",
    "plt.title('Boxplot of weight')\n",
    "plt.ylabel('Weight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_df['weight'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some outliers, more concentrated on the upper whisker. This, together with the other characteristics of the boxplot suggests positive skewness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a numerical attribute. Duplicates are allowed for obvious reasons. We check null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(cyclists_df['height'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2991 ```NaN``` values for the ```height``` attribute. As mentioned above, it is very likely to find a ```NaN``` in ```height``` column when even ```weight``` is ```NaN```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(cyclists_df['height'].dropna(), binwidth=1)\n",
    "plt.title('height distribution')\n",
    "plt.xlabel('height')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 10))\n",
    "sns.boxplot(y=cyclists_df['height'])\n",
    "plt.title('Boxplot of height')\n",
    "plt.ylabel('Height')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_df['height'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some outliers, this time concentrated more or less equally beyond both the whiskers. The boxplot, together with the histogram plotted before, suggest a relatively symmetric distribution of the ```height``` values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nationality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a categorical attribute. Duplicates are allowed. We check the presence of null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(cyclists_df['nationality'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_df[cyclists_df['nationality'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is only one null value in the ```nationality``` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_df['nationality'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the unique values of ```nationality``` there are apparently no problematic values in the column. All values are semantically and syntactically (check!!!) correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='nationality', data=cyclists_df, order=cyclists_df['nationality'].value_counts().index)\n",
    "plt.title('Histogram of Nationality')\n",
    "plt.xlabel('Nationality')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=90)  # Rotate x-axis labels for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the coefficients\n",
    "coefficients = ['spearman', 'pearson', 'kendall']\n",
    "\n",
    "# Plot the correlation matrices\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "for i, c in enumerate(coefficients):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    correlation_matrix = cyclists_df[cyclists_numeric].corr(method=c)\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "    plt.title(f'{c.capitalize()} Correlation Matrix')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix excluding non-numeric columns\n",
    "correlation_matrix = cyclists_df[cyclists_numeric].corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Matrix of Cyclists Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Races Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df = pd.read_csv('../dataset/races.csv')\n",
    "\n",
    "races_numeric_stage = [\"length\", \"climb_total\", \"startlist_quality\", \"average_temperature\"]\n",
    "races_numeric = [\"position\", \"cyclist_age\", \"delta\"]\n",
    "races_categorical = [\"points\", \"uci_points\", \"profile\"]\n",
    "races_binary = [\"is_tarmac\", \"is_cobbled\", \"is_gravel\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Basic Checks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### • Attributes types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### • Check null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of null values for each column\n",
    "null_counts = races_df.isnull().sum()\n",
    "\n",
    "# Plot the histogram\n",
    "ax = null_counts.plot(kind='bar', figsize=(10, 6), title='Histogram of Null Values for Each Column in Races Dataset')\n",
    "plt.xlabel('Attributes')\n",
    "plt.ylabel('Number of Null Values')\n",
    "\n",
    "# Add y values over the columns, rotating only for \"climb_total\" and \"profile\"\n",
    "for i, v in enumerate(null_counts):\n",
    "    if null_counts.index[i] in [\"climb_total\", \"profile\"]:\n",
    "        ax.text(i, v + 50, str(v), ha='center', va='bottom', rotation=45)\n",
    "    else:\n",
    "        ax.text(i, v + 50, str(v), ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### • Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easy to observe that for each entry related to a stage of a race, different cyclists should be associated. We therefore check that this is true and that there are no duplicates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by '_url' and 'cyclist' and count the occurrences\n",
    "duplicate_cyclists = races_df.groupby(['_url', 'cyclist']).size().reset_index(name='count')\n",
    "\n",
    "# Filter the groups where count is greater than 1\n",
    "duplicate_cyclists = duplicate_cyclists[duplicate_cyclists['count'] > 1]\n",
    "\n",
    "# Display the duplicate cyclists\n",
    "print(duplicate_cyclists)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that there are 123 duplicates in the dataset that should be handled during the data preparation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Count the duplicate values in the 'cyclist' column with the same value in the '_url' column\n",
    "# duplicate_counts = races_df.groupby('_url')['cyclist'].value_counts()\n",
    "\n",
    "# # filter only cyclists duplicated in the same stage\n",
    "# duplicate_counts = duplicate_counts[duplicate_counts > 1]\n",
    "\n",
    "# duplicate_counts.to_csv('../dataset/cyclist_duplicate.csv', header=True)\n",
    "\n",
    "# #count number of total duplicates in the races dataset\n",
    "# print(\"Number of total duplicates in the races dataset: \", duplicate_counts.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### • Unique values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking unique values for each column in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_points_count = races_df.nunique()\n",
    "print(\"Number of distinct values in 'points':\", distinct_points_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important thing we want to assess is that details of a stage are the same i.e. there are no inconsistent entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_attributes = [\"name\", \"points\", \"uci_points\", \"length\", \"climb_total\", \n",
    "                   \"startlist_quality\", \"average_temperature\", \"is_tarmac\"] #TODO: siamo sicuri che ci siano tutti gli attributi?\n",
    "\n",
    "# Initialize an empty list to store _url values where inconsistencies are found\n",
    "inconsistent_urls = []\n",
    "\n",
    "# Check for each attribute in race_attributes\n",
    "for attribute in race_attributes:\n",
    "    # Group by _url and check if all values in the group are the same\n",
    "    inconsistent = races_df.groupby('_url')[attribute].nunique() > 1\n",
    "    # Append the _url values with inconsistencies to the list\n",
    "    inconsistent_urls.extend(inconsistent[inconsistent].index.tolist())\n",
    "\n",
    "# Display the inconsistent _url values\n",
    "print(\"Inconsistent _url values:\", len(inconsistent_urls))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_numeric_stage = [\"length\", \"climb_total\", \"startlist_quality\", \"average_temperature\"]\n",
    "\n",
    "races_numeric_stage.append(\"_url\")\n",
    "\n",
    "numeric_df = races_df[races_numeric_stage].groupby(\"_url\").first().reset_index()\n",
    "\n",
    "numeric_df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Columns Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### • 'url' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df['_url'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This column contains the unique identifier of a race's stage. There are in total 5281 different _url values. An _url is in the format \"RACE_NAME/RACE_DATE/STAGE_NUMBER\". For example, the URL \"tour-de-france/1978/stage-6\" denotes the 6th stage of the Tour de France, 1978 edition. It is associated to some race stage details TODO: evaluate adding which are the details?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, if we look only at the column itself, we will find duplicate values. However, by looking at the first ten rows of the table, we assume that there is an entry for each rider who participated in a given stage. Given this observation, we already checked that there are no duplicates for the same stage in terms of participating riders (see the above Duplicate section for the results)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • Name column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attribute is categorical. First of all we check if there are null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df['name'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df['name'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no null values in the column which contains 61 unique values. They are the names of different races. We show those values to check in a qualitative way if there are some errors TODO: check the correct term to identify errors (e.g. \"asfdnajsfa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df['name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the _url column at the first '/' and take the first part\n",
    "race_names = races_df['_url'].str.split('/', n=1).str[0]\n",
    "# Count the unique values\n",
    "race_names.nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in races_df.groupby('name'):\n",
    "    print(f\"Race Name: {name}\")\n",
    "    unique_urls = group['_url'].str.split('/', n=1).str[0].unique()\n",
    "    print(unique_urls)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the total race names used in the unique identifier are only 27. This is because, as we show below, the same RACE_NAME part of the identifier is associated to different values in the names column. This does not mean that the same identifier is associated with different races. Rather, the values in the name column for the same race differ only by a few letters (e.g. e instead of è) or because the race has adopted a different name over the years or is simply known by different names. \n",
    "\n",
    "In particular:\n",
    "- ```san-sebastian``` is associated to _Clasica Ciclista San Sebastian_, _Clásica Ciclista San Sebastian_, _Clásica Ciclista San Sebastián_, _Clásica San Sebastián_, _Donostia San Sebastian Klasikoa_\n",
    "- ```dauphine``` is associated to _Criterium du Dauphiné_, _Criterium du Dauphiné Libére_, _Critérium du Dauphiné_, _Critérium du Dauphiné Libéré_\n",
    "- ```dwars-door-vlaanderen``` is associated to _Dwars door België / À travers la Belgique_, _Dwars door Vlaanderen_, _Dwars door Vlaanderen - A travers la Flandre ME_, _Dwars door Vlaanderen / A travers la Flandre_, _Dwars door Vlaanderen / A travers la Flandre ME_\n",
    "- ```e3-harelbeke``` is associated to _E3 BinckBank Classic_, _E3 Harelbeke_, _E3 Prijs Vlaanderen_, _E3 Prijs Vlaanderen - Harelbeke_, _E3 Saxo Bank Classic_, _E3 Saxo Classic_, _E3-Prijs Harelbek_\n",
    "- ```gp-quebec``` is associated to _Grand Prix Cycliste de Quebec_, _Grand Prix Cycliste de Québec_\n",
    "- ```liege-bastogne-liege``` is associated to _Liège - Bastogne - Liège_, _Liège-Bastogne-Liège_\n",
    "- ```strade-bianche``` is associated to _Monte Paschi Eroica_, _Montepaschi Strade Bianche - Eroica Toscana_, _Strade Bianche_\n",
    "- ```omloop-het-nieuwsblad``` is associated to _Omloop Het Nieuwsblad ME_, _Omloop Het Volk_, _Omloop Het Volk ME_\n",
    "- ```paris-roubaix``` is associated to _Paris - Roubaix_, _Paris-Roubaix_\n",
    "- ```ronde-van-vlaanderen``` is associated to _Ronde van Vlaanderen - Tour des Flandres ME_, _Ronde van Vlaanderen / Tour des Flandres_, _Ronde van Vlaanderen / Tour des Flandres ME_\n",
    "- ```volta-a-catalunya``` is associated to _Volta Ciclista a Catalunya_, _Volta a Catalunya_\n",
    "- ```itzulia-basque-country``` is associated to _Vuelta Ciclista al País Vasco_, _Vuelta al País Vasco_\n",
    "- ```world-championship``` is associated to _World Championships - Road Race_, _World Championships ME - Road Race_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### points column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a numerical attribute. Same points for different cyclist are supposedly allowed. We check now for null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(races_df['points'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df['points'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df['points'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(races_df['points'].dropna(), bins=30, kde=False)\n",
    "plt.title('Histogram of Points')\n",
    "plt.ylabel('Points')\n",
    "plt.xlabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(y=races_df['points'])\n",
    "plt.title('Boxplot of Points')\n",
    "plt.ylabel('Points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### uci_point column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(races_df['uci_points'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df['uci_points'].dropna().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.histplot(races_df['uci_points'].dropna(), bins=30, kde=False)\n",
    "\n",
    "# Add text labels on each bin with rotation\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    if height > 0:\n",
    "        ax.annotate(f'{int(height)}', (p.get_x() + p.get_width() / 2. + 0.1, height),\n",
    "                    ha='center', va='center', xytext=(0, 25), textcoords='offset points', rotation=90)\n",
    "\n",
    "# Set titles and labels\n",
    "plt.title('Histogram of count values for UCI Points attribute')\n",
    "plt.xlabel('UCI Points')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(races_df['uci_points'].dropna(), bins=30, kde=False)\n",
    "plt.title('Histogram of UCI Points')\n",
    "plt.ylabel('UCI Points')\n",
    "plt.xlabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 10))\n",
    "sns.boxplot(y=races_df['uci_points'])\n",
    "plt.title('Boxplot of UCI Points')\n",
    "plt.ylabel('Points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### length column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(races_df['length'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df['length'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Controllo se le lunghezze delle tappe sono consistenti. Per tutte le copie di una tappa deve risultare sempre la stessa lunghezza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by '_url' and filter out null values in 'length'\n",
    "length_consistency = races_df[~races_df['length'].isnull()].groupby('_url')['length'].nunique()\n",
    "\n",
    "# Count the number of cases where the length is not consistent\n",
    "inconsistent_length_count = (length_consistency > 1).sum()\n",
    "\n",
    "inconsistent_length_count\n",
    "#print(f\"Number of cases where the length is not consistent: {inconsistent_length_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "poichè c'è coerenza è possobile raggruppare su _url per controllare le lunghezze delle tappe così da non conisderare duplicati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raggruppa per '_url' e calcola la lunghezza media delle gare\n",
    "grouped_races_df = races_df.groupby('_url').first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_grouped_length = grouped_races_df['length'].mean()\n",
    "print(f\"La lunghezza media delle gare raggruppate è: {average_grouped_length:.2f} metri\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(races_df['length'].dropna(), binwidth=5000)\n",
    "plt.title('Distribution of Length Attribute')\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 10))\n",
    "sns.boxplot(y=grouped_races_df['length'])\n",
    "plt.title('Boxplot of Race Length')\n",
    "plt.ylabel('Length (meters)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "credo sotto i 50km siano tutti da scartare ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_stages_count = (grouped_races_df['length'] < 50000).sum()\n",
    "print(f\"Number of stages under 50 km: {short_stages_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df['length'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### climb_total column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of climb null\n",
    "int(races_df['climb_total'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by '_url' and filter out null values in 'length'\n",
    "climb_consistency = races_df[~races_df['climb_total'].isnull()].groupby('_url')['climb_total'].nunique()\n",
    "\n",
    "# Count the number of cases where the climb is not consistent\n",
    "inconsistent_length_count = (climb_consistency > 1).sum()\n",
    "\n",
    "inconsistent_length_count\n",
    "#print(f\"Number of cases where the length is not consistent: {inconsistent_length_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(y=grouped_races_df['climb_total'])\n",
    "plt.title('Boxplot of Race Length')\n",
    "plt.ylabel('Length (meters)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column of interest\n",
    "total_climb = grouped_races_df['climb_total']\n",
    "\n",
    "# Create a DataFrame to store the statistics\n",
    "stats_df = pd.DataFrame({\n",
    "    'Statistic': ['Null Count', 'Unique Value Counts', 'Mean', 'Max', 'Min', 'Variance', 'Description'],\n",
    "    'Value': [\n",
    "        total_climb.isnull().sum(),\n",
    "        total_climb.nunique(),\n",
    "        total_climb.mean(),\n",
    "        total_climb.max(),\n",
    "        total_climb.min(),\n",
    "        total_climb.var(),\n",
    "        total_climb.describe().to_dict()\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### profile column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FRANCESCO P. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### position column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(races_df['position'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the same stage, we check if there are duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by '_url' and check for duplicate positions within each group\n",
    "duplicate_positions = races_df.groupby('_url')['position'].apply(lambda x: x.duplicated(keep=False)).reset_index(drop=True)\n",
    "\n",
    "# Filter the DataFrame to show only the rows with duplicate positions\n",
    "races_df[duplicate_positions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(races_df['position'], bins=30, kde=False)\n",
    "plt.title('Histogram of Position')\n",
    "plt.xlabel('Position')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```cyclist``` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df['cyclist'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no null values in the column. Duplicated are expected but we check if, for the same stage of a race, there are no duplicated cyclists values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df[races_df.duplicated(subset=['_url', 'cyclist'], keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the table above, for the same stage, there are duplicated ```cyclist``` values. We can also notice that in the same rows of a duplicate there are also other altered values like ```date```, ```positivon``` or ```delta```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```cyclist_age``` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a numerical attribute. First of all we check if there are null values and if all the entries are numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df['cyclist_age'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df['cyclist_age'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are 113 null entries but the remaining values are numerical.\n",
    "\n",
    "Duplicates in the column are allowed but no for the same cyclist which can be also duplicated for the same stage as we checked in the previous column analysis. We check if the age reported for each cyclist is consistent across the column to gather more informations for the DP part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'cyclist' and check if there are different 'cyclist_age' values\n",
    "age_inconsistencies = races_df.groupby('cyclist')['cyclist_age'].nunique()\n",
    "\n",
    "# Filter the cyclists with more than one unique age value\n",
    "age_inconsistencies[age_inconsistencies > 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected the same cyclist is associated to more than one age value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(races_df['cyclist_age'].dropna(), bins=30)\n",
    "plt.title('Histogram of Cyclist Age')\n",
    "plt.xlabel('Cyclist Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 10))\n",
    "sns.boxplot(y=races_df['cyclist_age'])\n",
    "plt.title('Boxplot of Cyclist Age')\n",
    "plt.ylabel('Cyclist Age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```is_tarmac``` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a boolean column. We check the presence of null values, errors, and we plot the distribution of the True and False values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df['is_tarmac'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df['is_tarmac'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 10))\n",
    "sns.histplot(races_df['is_tarmac'], bins=2)\n",
    "plt.title('Histogram of Is Tarmac')\n",
    "plt.xlabel('Is Tarmac')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks([0, 1], ['False', 'True'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FRANCESCO ALIP:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the coefficients\n",
    "coefficients = ['spearman']\n",
    "\n",
    "# Exclude the '_url' column from the numeric columns list\n",
    "races_numeric_stage_no_url = [col for col in races_numeric_stage + races_numeric + races_categorical if col != '_url']\n",
    "\n",
    "# Plot the correlation matrices\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "for i, c in enumerate(coefficients):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    correlation_matrix = races_df[races_numeric_stage_no_url].corr(method=c)\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "    plt.title(f'{c.capitalize()} Correlation Matrix')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include the 'profile' attribute in the numeric columns list\n",
    "races_numeric_stage_with_profile = races_numeric_stage_no_url + ['profile']\n",
    "\n",
    "# Calculate the correlation matrix including the 'profile' attribute\n",
    "correlation_matrix_with_profile = races_df[races_numeric_stage_with_profile].corr(method='spearman')\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix_with_profile, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Matrix Including Profile Attribute')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEATURE ENGENEERING TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essendo il ciclismo uno sport in cui mediamente a parità di altezza il peso è simile, raggruppiamo per categoria l'altezza con intervalli di 5cm per cercare possibili outliers nel peso utilizzando dei boxplot condizionali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bins for the height category\n",
    "bins = [154, 159, 164, 169, 174, 179, 184, 189, 194, 199, 204]\n",
    "labels = list(range(10))\n",
    "\n",
    "# Create a new column with the height category mantaining the null values\n",
    "cyclists_df['height_category'] = pd.cut(cyclists_df['height'], bins=bins, labels=labels, right=False, include_lowest=True)\n",
    "\n",
    "# Show the first 20 rows of the height and height_category columns\n",
    "print(cyclists_df[['height', 'height_category']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='height_category', y='weight', data=cyclists_df)\n",
    "plt.title('Boxplot of Weight Conditioned on Height Category')\n",
    "plt.xlabel('Height Category')\n",
    "plt.ylabel('Weight')\n",
    "\n",
    "# Set y-axis intervals\n",
    "plt.yticks(np.arange(50, cyclists_df['weight'].max() + 5, 5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizziamo il numero di ciclisti per ogni categoria che abbiamo definito (escludendo quelli con peso nullo) per valutare se il numero di outlier ottenuti dai boxplot è significativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude cyclists with null weight\n",
    "cyclists_df_non_null_weight = cyclists_df[cyclists_df['weight'].notnull()]\n",
    "\n",
    "# Count the number of cyclists in each height category\n",
    "height_category_counts = cyclists_df_non_null_weight['height_category'].value_counts().sort_index()\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = height_category_counts.plot(kind='bar')\n",
    "plt.title('Number of Cyclists per Height Category (Excluding Null Weights)')\n",
    "plt.xlabel('Height Category')\n",
    "plt.ylabel('Number of Cyclists')\n",
    "\n",
    "# Add the count above each bin\n",
    "for i, count in enumerate(height_category_counts):\n",
    "    ax.text(i, count + 5, str(count), ha='center', va='bottom')\n",
    "\n",
    "# Rotate x-axis labels to horizontal\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycountry_convert as pc\n",
    "\n",
    "# Function to convert country name to continent\n",
    "def country_to_continent(country_name):\n",
    "    try:\n",
    "        country_alpha2 = pc.country_name_to_country_alpha2(country_name)\n",
    "        continent_code = pc.country_alpha2_to_continent_code(country_alpha2)\n",
    "        continent_name = pc.convert_continent_code_to_continent_name(continent_code)\n",
    "        return continent_name\n",
    "    except:\n",
    "        return 'Unknown'\n",
    "\n",
    "# Apply the function to create a new column 'continent'\n",
    "cyclists_df['continent'] = cyclists_df['nationality'].apply(country_to_continent)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(cyclists_df[['nationality', 'continent']].head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pairplot excluding the 'height_category' column\n",
    "sns.pairplot(cyclists_df.drop(columns=['height_category']), hue='continent')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elements in 'cyclist' column of races_data and not in '_url' column of cyclists_data\n",
    "diff_races_not_in_cyclists = np.setdiff1d(races_df['cyclist'].unique(), cyclists_df['_url'].unique())\n",
    "print(\"In 'races_data' but not in 'cyclists_data':\", diff_races_not_in_cyclists)\n",
    "\n",
    "# Elements in '_url' column of cyclists_data and not in 'cyclist' column of races_data\n",
    "diff_cyclists_not_in_races = np.setdiff1d(cyclists_df['_url'].unique(), races_df['cyclist'].unique())\n",
    "print(\"In 'cyclists_data' but not in 'races_data':\", diff_cyclists_not_in_races)\n",
    "\n",
    "print(races_df['cyclist'].unique().size)\n",
    "\n",
    "len(diff_cyclists_not_in_races)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
